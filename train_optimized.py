import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_squared_error, accuracy_score
from sklearn.model_selection import TimeSeriesSplit

# --- CONFIGURATION ---
DATA_FOLDER = "data"
FILE_PATH = os.path.join(DATA_FOLDER, "ALL_YFINANCE_features.csv")
TARGET_SYMBOL = "MSFT"  # On se concentre sur Microsoft pour commencer (plus propre)

# On garde les m√™mes features
FEATURES = [
    "RSI_14", 
    "MACD", "MACD_Signal", "MACD_Diff", 
    "Bollinger_Width", "Bollinger_%B",
    "Return", "Volume"
]

def train_optimized():
    print(f"\n D√âMARRAGE V2 (Optimis√©) sur {TARGET_SYMBOL}...")
    
    # 1. Chargement & Filtrage
    if not os.path.exists(FILE_PATH):
        print(f" Fichier introuvable : {FILE_PATH}")
        return
    
    df_all = pd.read_csv(FILE_PATH)
    
    # FILTRE SUR UN SEUL SYMBOLE (Crucial pour d√©buter)
    df = df_all[df_all["symbol"] == TARGET_SYMBOL].copy()
    
    # Nettoyage
    df = df.dropna().reset_index(drop=True)
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"])
        df = df.sort_values("date")
    
    print(f"Donn√©es filtr√©es pour {TARGET_SYMBOL} : {len(df)} jours de trading.")

    # 2. Split Temporel (80% Train / 20% Test)
    split_idx = int(len(df) * 0.8)
    
    # On pr√©pare les donn√©es
    X = df[FEATURES]
    y_return = df["Return_next"]  # CIBLE = % de variation (et non le prix)
    y_class = (df["Return_next"] > 0).astype(int) # CIBLE = Hausse/Baisse
    
    # Prix r√©els (pour la reconstruction √† la fin)
    prices = df["Close"]
    prices_test = prices.iloc[split_idx:]
    
    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
    y_ret_train, y_ret_test = y_return.iloc[:split_idx], y_return.iloc[split_idx:]
    y_class_train, y_class_test = y_class.iloc[:split_idx], y_class.iloc[split_idx:]
    
    # ====================================================
    # 3. R√âGRESSION OPTIMIS√âE (Pr√©dire le Rendement)
    # ====================================================
    print("\n Entra√Ænement R√©gression (Objectif : Return_next)...")
    
    # On augmente un peu la puissance du mod√®le
    rf_reg = RandomForestRegressor(n_estimators=200, min_samples_leaf=5, random_state=42, n_jobs=-1)
    rf_reg.fit(X_train, y_ret_train)
    
    # Pr√©diction du % de variation
    pred_returns = rf_reg.predict(X_test)
    
    # --- RECONSTRUCTION DU PRIX ---
    # Prix_Predit = Prix_Hier * (1 + Return_Predit)
    # Attention : Pour pr√©dire J+1, on utilise le prix de J (qui est dans X_test, mais il faut le r√©cup√©rer)
    # Ici, prices_test correspond aux prix de J ("Close"). On veut pr√©dire "Close_next".
    
    predicted_prices = prices_test * (1 + pred_returns)
    true_prices_next = df["Close_next"].iloc[split_idx:] # La vraie cible J+1
    
    # Baseline Na√Øve : On pr√©dit que Prix_J+1 = Prix_J
    naive_prices = prices_test
    
    # Calcul des erreurs
    rmse_model = np.sqrt(mean_squared_error(true_prices_next, predicted_prices))
    rmse_naive = np.sqrt(mean_squared_error(true_prices_next, naive_prices))
    
    print(f"--- R√âSULTATS R√âGRESSION ({TARGET_SYMBOL}) ---")
    print(f"RMSE Mod√®le (Via Return) : {rmse_model:.4f} $")
    print(f"RMSE Na√Øf (Baseline)     : {rmse_naive:.4f} $")
    
    if rmse_model < rmse_naive:
        print(" VICTOIRE : Le mod√®le bat la baseline na√Øve !")
    elif rmse_model < rmse_naive * 1.05:
        print(" √âGALIT√â : Le mod√®le est tr√®s proche de la baseline (C'est bon signe).")
    else:
        print(" D√âFAITE : Encore un peu de travail (Feature Engineering n√©cessaire).")

    # ====================================================
    # 4. CLASSIFICATION (Direction)
    # ====================================================
    print("\nüé≤ Entra√Ænement Classification...")
    rf_class = RandomForestClassifier(n_estimators=200, min_samples_leaf=5, random_state=42, n_jobs=-1)
    rf_class.fit(X_train, y_class_train)
    
    pred_class = rf_class.predict(X_test)
    acc_model = accuracy_score(y_class_test, pred_class)
    
    # Baseline
    acc_baseline = accuracy_score(y_class_test, [y_class_train.mode()[0]] * len(y_class_test))
    
    print(f"--- R√âSULTATS CLASSIFICATION ({TARGET_SYMBOL}) ---")
    print(f"Pr√©cision IA     : {acc_model*100:.2f}%")
    print(f"Pr√©cision Hasard : {acc_baseline*100:.2f}%")
    
    if acc_model > acc_baseline:
        print(f" VICTOIRE : +{acc_model*100 - acc_baseline*100:.2f} points au-dessus du hasard.")
    else:
        print(" D√âFAITE : Difficile de battre le march√©.")

    # ====================================================
    # 5. VISUALISATION (Pour comprendre)
    # ====================================================
    print("\n G√©n√©ration du graphique de pr√©diction...")
    plt.figure(figsize=(12, 6))
    # On affiche juste les 100 derniers jours pour y voir clair
    subset_true = true_prices_next.iloc[-100:]
    subset_pred = predicted_prices.iloc[-100:]
    subset_naive = naive_prices.iloc[-100:]
    
    plt.plot(subset_true.index, subset_true.values, label="Prix R√©el", color="black", linewidth=2)
    plt.plot(subset_pred.index, subset_pred.values, label="Pr√©diction IA (Via Returns)", color="green", linestyle="--")
    plt.plot(subset_naive.index, subset_naive.values, label="Na√Øf (J-1)", color="red", alpha=0.3)
    
    plt.title(f"Pr√©diction {TARGET_SYMBOL} : IA vs R√©alit√©")
    plt.legend()
    plt.savefig(os.path.join(DATA_FOLDER, "prediction_v2.png"))
    print("Graphique sauvegard√© : data/prediction_v2.png")

if __name__ == "__main__":
    train_optimized()
