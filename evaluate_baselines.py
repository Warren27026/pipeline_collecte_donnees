import os
import pandas as pd
import numpy as np
from sklearn.dummy import DummyClassifier
from sklearn.metrics import mean_squared_error, accuracy_score

# Configuration des chemins
DATA_FOLDER = "data"
# On utilise le fichier contenant toutes les features calcul√©es
FILE_PATH = os.path.join(DATA_FOLDER, "ALL_YFINANCE_features.csv")

def evaluate_baselines():
    """
    Calcule et affiche les performances des mod√®les de r√©f√©rence (Baselines).
    Ce sont les scores minimums que le futur mod√®le ML doit battre.
    """
    
    # 1. Chargement des donn√©es
    if not os.path.exists(FILE_PATH):
        print(f"[ERREUR] Le fichier de donn√©es est introuvable : {FILE_PATH}")
        print("Assurez-vous d'avoir lanc√© 'donne_collectes_nettoye.py' avant.")
        return

    print(f"\n--- CHARGEMENT DES DONN√âES : {FILE_PATH} ---")
    df = pd.read_csv(FILE_PATH)
    
    # Nettoyage : On a besoin de la cible (Close_next) et des features
    # On supprime les lignes o√π les valeurs futures (Target) ne sont pas encore connues (le dernier jour)
    df = df.dropna(subset=["Close", "Close_next", "Return_next"])
    
    if df.empty:
        print("[ERREUR] Pas assez de donn√©es pour l'√©valuation (DataFrame vide apr√®s nettoyage).")
        return
        
    print(f"Nombre d'√©chantillons √©valu√©s : {len(df)}")

    print("\n" + "="*50)
    print("   1. BASELINE DE R√âGRESSION (Pr√©diction de Prix)")
    print("="*50)
    
    # --- MOD√àLE NA√èF (Persistence Model) ---
    # Hypoth√®se : Le prix de demain sera identique au prix d'aujourd'hui.
    # C'est souvent difficile √† battre en finance sur des horizons tr√®s courts.
    
    y_true_price = df["Close_next"]  # La r√©alit√©
    y_pred_naive = df["Close"]       # La pr√©diction na√Øve (J = J-1)
    
    # Calcul de l'erreur quadratique moyenne (RMSE)
    rmse_naive = np.sqrt(mean_squared_error(y_true_price, y_pred_naive))
    
    print(f"Mod√®le : Naive Prediction (Prix(J+1) = Prix(J))")
    print(f"Metric : RMSE (Root Mean Squared Error)")
    print(f"--------------------------------------------------")
    print(f" ERREUR MOYENNE (RMSE) : {rmse_naive:.4f} $")
    print(f"--------------------------------------------------")
    print(f"üëâ OBJECTIF : Le mod√®le IA (Random Forest/LSTM) devra avoir une RMSE < {rmse_naive:.4f} $")
    print(f"   (Sinon, il est moins bon qu'une simple copie du prix de la veille)")


    print("\n" + "="*50)
    print("   2. BASELINE DE CLASSIFICATION (Achat / Vente)")
    print("="*50)
    
    # --- MOD√àLE STATISTIQUE (Dummy Classifier) ---
    # Hypoth√®se : On pr√©dit toujours la classe majoritaire.
    # Exemple : Si le march√© monte 55% du temps, pr√©dire "HAUSSE" tout le temps donne 55% de r√©ussite.
    
    # Cr√©ation de la cible binaire : 1 si le rendement demain est positif (Hausse), 0 sinon (Baisse)
    df["Target_Binary"] = (df["Return_next"] > 0).astype(int)
    
    X = df[["Close"]] # Feature fictive (le Dummy s'en fiche)
    y = df["Target_Binary"]
    
    # Initialisation du Dummy Classifier de Scikit-Learn
    # strategy="most_frequent" -> Pr√©dit toujours la classe la plus repr√©sent√©e
    dummy_clf = DummyClassifier(strategy="most_frequent")
    dummy_clf.fit(X, y)
    
    # Pr√©diction et Score
    score_dummy = dummy_clf.score(X, y)
    class_majoritaire = "HAUSSE" if dummy_clf.predict([0])[0] == 1 else "BAISSE"
    
    print(f"Mod√®le : Dummy Classifier (Strat√©gie 'Most Frequent')")
    print(f"Classe majoritaire d√©tect√©e : {class_majoritaire}")
    print(f"--------------------------------------------------")
    print(f"PR√âCISION DE R√âF√âRENCE (Accuracy) : {score_dummy*100:.2f} %")
    print(f"--------------------------------------------------")
    print(f"OBJECTIF : Notre mod√®le IA devra avoir une pr√©cision > {score_dummy*100:.2f} %")
    print(f"   (Attention : 50% n'est pas la r√©f√©rence si le march√© est haussier, c'est ce chiffre qu'il faut battre)")

if __name__ == "__main__":
    evaluate_baselines()
